{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "import json\n",
    "import urllib.request \n",
    "import re, os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# preprocessing, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "# helper functions\n",
    "from helperFunctions import *\n",
    "\n",
    "# naive bayes implementation\n",
    "from naiveBayes import *\n",
    "\n",
    "# evaluation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
    "dataset = 'True.csv' # Fake.csv\n",
    "pathToDataFiles = './datafiles/'\n",
    "df = pd.read_csv('dataset/' + dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all textual input, discard the rest (except for the labels)\n",
    "df.text = df.title + ' ' + df.text\n",
    "df.rename(columns={'subject': 'label'},\n",
    "          inplace=True, errors='raise')\n",
    "df.drop(['title', 'date'], axis=1, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse and Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['politicsNews', 'worldnews'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the dataset balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<AxesSubplot:>,\n",
       " politicsNews    11272\n",
       " worldnews       10145\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = df['label'].value_counts().sort_values(ascending=False)\n",
    "counts.plot(kind='bar'), counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  As U.S. budget fight looms, Republicans flip t...      0\n",
       "1  U.S. military to accept transgender recruits o...      0\n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...      0\n",
       "3  FBI Russia probe helped by Australian diplomat...      0\n",
       "4  Trump wants Postal Service to charge 'much mor...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df.label = le.fit_transform(df.label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text, remove symbols and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  As U.S. budget fight looms, Republicans flip t...      0\n",
       "1  U.S. military to accept transgender recruits o...      0\n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...      0\n",
       "3  FBI Russia probe helped by Australian diplomat...      0\n",
       "4  Trump wants Postal Service to charge 'much mor...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this needs alot of cpu AND ram resources\n",
    "#df['text'] = df['text'].apply(preprocessNLFeature)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('dataset_preprocessed-' + dataset, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of dataset because ngram is very time consuming\n",
    "df = pd.read_csv('dataset_preprocessed-' + dataset, sep='\\t') #.sample(frac=0.1, replace=False, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, validation, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exclusive pentagon lockheed near deal billion ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>france says saudi coalition must boost aid eff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u.s. renews call cambodia release opposition l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>treasury 's mnuchin trump 's proposed corporat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>romanian ruling party leader investigated 'cri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  exclusive pentagon lockheed near deal billion ...      0\n",
       "1  france says saudi coalition must boost aid eff...      1\n",
       "2  u.s. renews call cambodia release opposition l...      1\n",
       "3  treasury 's mnuchin trump 's proposed corporat...      0\n",
       "4  romanian ruling party leader investigated 'cri...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train val test relation -> 60:20:20\n",
    "trainval, test = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "train, val = train_test_split(trainval, test_size=0.25, random_state=12345)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prep validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val.label\n",
    "val.drop('label', axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with counting occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Frequency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~cubic complexity, very time consuming\n",
    "#freq_tb_occ, uniques_occ = frequencyTableOccurences(train.text, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('freq_tb-occurences-' + dataset, freq_tb_occ)\n",
    "#np.save('uniques-occurences-' + dataset, uniques_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('freq_tb-occurences-' + dataset + '.npy', 'rb') as f:\n",
    "    freq_tb_occ = np.load(f)\n",
    "with open('uniques-occurences-' + dataset + '.npy', 'rb') as f:\n",
    "    uniques_occ = np.load(f).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create likelyhood table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to merge all information into one table\n",
    "sumRowsRel, sumColsRel = likelihoodTable(freq_tb_occ)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run prediction for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' y_pred = []\\nfor d in val.text:\\n    y_pred.append(predictDoc(d.split(), uniques_occ, freq_tb_occ, sumRowsRel, sumColsRel)) '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" y_pred = []\n",
    "for d in val.text:\n",
    "    y_pred.append(predictDoc(d.split(), uniques_occ, freq_tb_occ, sumRowsRel, sumColsRel)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" df_results_occ = pd.DataFrame(val.text)\\ndf_results_occ['label'] = y_val\\ndf_results_occ['prediction'] = y_pred\\ndf_results_occ['TPTN'] = df_results_occ.label == df_results_occ.prediction\\ndf_results_occ.head() \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" df_results_occ = pd.DataFrame(val.text)\n",
    "df_results_occ['label'] = y_val\n",
    "df_results_occ['prediction'] = y_pred\n",
    "df_results_occ['TPTN'] = df_results_occ.label == df_results_occ.prediction\n",
    "df_results_occ.head() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "presist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_occ.to_csv('naive-bayes-occurences-results-' + dataset, sep='\\t', index=False)\n",
    "df_results_occ = pd.read_csv('naive-bayes-occurences-results-' + dataset, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with counting N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial tests were made with n = 6, \n",
    "# but the chances of 6 words being repeated in the same order are very slim\n",
    "# so I gradually reduced the size of the ngrams\n",
    "\n",
    "n = 2\n",
    "train['ngrams'] = train.text.apply(createNgrams, args=[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~down to quadratic complexity\n",
    "#freq_tb_ng, uniques_ng = frequencyTableNgrams(train.ngrams, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" np.save('freq_tb-N-Grams-' + str(n) + '-' + dataset, freq_tb_ng)\\nwith open('uniques-N-Grams-' + str(n) + '-' + dataset + '.pkl', 'wb') as f:\\n    pickle.dump(uniques_ng, f) \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" np.save('freq_tb-N-Grams-' + str(n) + '-' + dataset, freq_tb_ng)\n",
    "with open('uniques-N-Grams-' + str(n) + '-' + dataset + '.pkl', 'wb') as f:\n",
    "    pickle.dump(uniques_ng, f) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('freq_tb-N-Grams-' + str(n) + '-' + dataset + '.npy', 'rb') as f:\n",
    "    freq_tb_ng = np.load(f)\n",
    "      \n",
    "with open('uniques-N-Grams-' + str(n) + '-' + dataset + '.pkl', 'rb') as f:\n",
    "    uniques_ng = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create likelihood table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to merge all information into one table\n",
    "sumRowsRel, sumColsRel = likelihoodTable(freq_tb_ng)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create n-grams in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['ngrams'] = val.text.apply(createNgrams, args=[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run prediction for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting document 0 of 9\n",
      "predicting document 1 of 9\n",
      "predicting document 2 of 9\n",
      "predicting document 3 of 9\n",
      "predicting document 4 of 9\n",
      "predicting document 5 of 9\n",
      "predicting document 6 of 9\n",
      "predicting document 7 of 9\n",
      "predicting document 8 of 9\n",
      "predicting document 9 of 9\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "progress = 0\n",
    "total = len(val.ngrams[:10])-1\n",
    "for listOfNgrams in val.ngrams[:10]:\n",
    "    print('predicting document', str(progress), 'of', str(total))\n",
    "    progress += 1\n",
    "    y_pred.append(predictDoc(listOfNgrams, uniques_ng, freq_tb_ng, sumRowsRel, sumColsRel, nclasses=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(16) as p:\n",
    "    y_p = p.map(partial(predictDoc, uniques=uniques_ng, freq_tb= freq_tb_ng, sumRowsRel=sumRowsRel, sumColsRel=sumColsRel, nclasses=2) , val.ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngrams</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>TPTN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(yemen, humanitarian), (humanitarian, situati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(erdogan, says), (says, turkey), (turkey, ira...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(republican, ryan), (ryan, raising), (raising...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(mexican, president), (president, asks), (ask...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(uk, government), (government, official), (of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ngrams  label  prediction   TPTN\n",
       "0  [(yemen, humanitarian), (humanitarian, situati...      1           0  False\n",
       "1  [(erdogan, says), (says, turkey), (turkey, ira...      1           1   True\n",
       "2  [(republican, ryan), (ryan, raising), (raising...      0           0   True\n",
       "3  [(mexican, president), (president, asks), (ask...      1           1   True\n",
       "4  [(uk, government), (government, official), (of...      1           1   True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_ng = pd.DataFrame(val.ngrams)\n",
    "df_results_ng['label'] = y_val\n",
    "df_results_ng['prediction'] = y_pred\n",
    "df_results_ng['TPTN'] = df_results_ng.label == df_results_ng.prediction\n",
    "df_results_ng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "df_results_ng = pd.read_csv(pathToDataFiles + 'naive-bayes-N-Grams-' + str(n) + '-results-' + dataset, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use weighted accuracy, since the dataset is unbalanced\n",
    "val_sample_weights = class_weight.compute_sample_weight('balanced', train.label._values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2775\n",
       "1    1734\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_occ = pd.read_csv(pathToDataFiles + 'naive-bayes-occurences-results-' + dataset, sep='\\t')\n",
    "df_results_ng = pd.read_csv(pathToDataFiles + 'naive-bayes-N-Grams-' + str(n) + '-results-' + dataset, sep='\\t')\n",
    "df_results_ng.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy of always predicting the most common class: 0.5092038145930361\n",
      "accuracy for NB with occurences count: 0.8298957640275005\n",
      "accuracy for NB with N-Grams of 2 count: 0.8582834331337326\n"
     ]
    }
   ],
   "source": [
    "counts = pd.Series(df_results_occ.label == 0).value_counts() # always guess the most common class\n",
    "acc = counts[1]/counts.sum()    # (TP + TN) / ALL\n",
    "print('baseline accuracy of always predicting the most common class:', acc)\n",
    "\n",
    "counts = df_results_occ.TPTN.value_counts()\n",
    "acc = counts[1]/counts.sum()\n",
    "print('accuracy for NB with occurences count:', acc)\n",
    "\n",
    "counts = df_results_ng.TPTN.value_counts()\n",
    "acc = counts[1]/counts.sum()\n",
    "print('accuracy for NB with N-Grams of ' + str(n) + ' count:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_weighted_accuracy=0.500\n",
      "NB with word occurences weighted accuracy=0.831\n",
      "NB with N-Grams of 2 weighted accuracy=0.856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# baseline, just guess one class all the time\n",
    "baseline_weighted_accuracy = balanced_accuracy_score(y_val, [0 for l in y_val])\n",
    "\n",
    "# Naive Bayes with count of word occurences\n",
    "occ_weighted_accuracy = balanced_accuracy_score(df_results_occ.label, df_results_occ.prediction)                                           \n",
    "\n",
    "# Naive Bayes with N-grams\n",
    "ng_weighted_accuracy = balanced_accuracy_score(df_results_ng.label, df_results_ng.prediction)\n",
    "\n",
    "\n",
    "print('baseline_weighted_accuracy=%.3f' %baseline_weighted_accuracy)\n",
    "print('NB with word occurences weighted accuracy=%.3f' %occ_weighted_accuracy)\n",
    "print('NB with N-Grams of ' + str(n) + ' weighted accuracy=%.3f' %ng_weighted_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec = vectorizer.fit_transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=True).fit(feature_vec)\n",
    "X_train_tf = tf_transformer.transform(feature_vec)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Adjust to own version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create train/test set\n",
    "train_data = train_text\n",
    "train_labels = train[\"author\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data,train_labels,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_features = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "])\n",
    "\n",
    "text_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('features', text_features),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = pipe.predict(X_test)\n",
    "nb_probs = pipe.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy score: \" + str(accuracy_score(y_test, nb_pred)))\n",
    "print(\"Log loss: \" + str(log_loss(y_test, nb_probs)));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd17a11ea7543847da29bd4e1a3a09b21faff0b9e29eed5ea605d70fe73d28e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
