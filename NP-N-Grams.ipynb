{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes counting N-Grams in documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "import json\n",
    "import urllib.request \n",
    "import re, os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# preprocessing, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "# helper functions\n",
    "from helperFunctions import *\n",
    "\n",
    "# naive bayes implementation\n",
    "from naiveBayes import *\n",
    "\n",
    "# evaluation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToDataFiles = './datafiles/'\n",
    "dataset = 'True.csv' # Fake.csv\n",
    "df = pd.read_csv(pathToDataFiles + 'dataset_preprocessed-' + dataset, sep='\\t')\n",
    "\n",
    "# N-Grams of length n\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train, validation, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>russian nuclear bombers fly near north korea r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>japanese man kills wife priestess sister sword...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokyo governor quits head conservative opposit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top international lawyers say hong kong rule l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spain rule exceptional measures catalonia madr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  russian nuclear bombers fly near north korea r...      1\n",
       "1  japanese man kills wife priestess sister sword...      1\n",
       "2  tokyo governor quits head conservative opposit...      1\n",
       "3  top international lawyers say hong kong rule l...      1\n",
       "4  spain rule exceptional measures catalonia madr...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train val test relation -> 60:20:20\n",
    "trainval, test = train_test_split(df, test_size=0.2, random_state=12345)\n",
    "train, val = train_test_split(trainval, test_size=0.25, random_state=12345)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prep validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val.label\n",
    "val.drop('label', axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Create n-grams in the validation set\n",
    "val['ngrams'] = val.text.apply(createNgrams, args=[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with counting N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial tests were made with n = 6, \n",
    "# but the chances of 6 words being repeated in the same order are very slim\n",
    "# so I gradually reduced the size of the ngrams\n",
    "\n",
    "train['ngrams'] = train.text.apply(createNgrams, args=[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~down to quadratic complexity\n",
    "#freq_tb_ng, uniques_ng = frequencyTableNgrams(train.ngrams, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" np.save(pathToDataFiles + 'freq_tb-N-Grams-' + str(n) + '-' + dataset, freq_tb_ng)\n",
    "with open(pathToDataFiles + 'uniques-N-Grams-' + str(n) + '-' + dataset + '.pkl', 'wb') as f:\n",
    "    pickle.dump(uniques_ng, f) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pathToDataFiles + 'freq_tb-N-Grams-' + str(n) + '-' + dataset + '.npy', 'rb') as f:\n",
    "    freq_tb_ng = np.load(f)\n",
    "      \n",
    "with open(pathToDataFiles + 'uniques-N-Grams-' + str(n) + '-' + dataset + '.pkl', 'rb') as f:\n",
    "    uniques_ng = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create likelihood table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to merge all information into one table\n",
    "sumRowsRel, sumColsRel = likelihoodTable(freq_tb_ng)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run prediction for the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict in batches to reduce ram usage and allow for splitted over night jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting documents from 0 to 10\n",
      "this iterations predictions: [0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
      "predicting documents from 10 to 20\n",
      "this iterations predictions: [1, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "predicting documents from 20 to 30\n",
      "this iterations predictions: [0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "predicting documents from 30 to 40\n",
      "this iterations predictions: [0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "predicting documents from 40 to 50\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "stop = 500\n",
    "stepSize = 10\n",
    "subfolderPredictions = 'predictions/'\n",
    "for i in range(0, stop, stepSize):\n",
    "    print('predicting documents from', i, 'to', i+stepSize)\n",
    "    y_pred = []\n",
    "    # got 4 theoretical cores and need to study -> 3\n",
    "    with Pool(3) as p:\n",
    "        y_pred.extend(\n",
    "            p.map(\n",
    "                partial(predictDoc, uniques=uniques_ng, freq_tb= freq_tb_ng, sumRowsRel=sumRowsRel, sumColsRel=sumColsRel, nclasses=2), \n",
    "                val.ngrams[i:i+stepSize]))\n",
    "        print('this iterations predictions:', y_pred)\n",
    "    dfPartialResults = pd.DataFrame(pd.Series(data=y_pred, name='prediction'))\n",
    "    dfPartialResults.to_csv(pathToDataFiles + subfolderPredictions + 'naive-bayes-N-Grams-' + str(n) + '-predictions-' + str(i) + '-' + dataset, sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prediction\n",
      "0           0\n",
      "1           0\n",
      "   prediction\n",
      "0           1\n",
      "1           0\n"
     ]
    }
   ],
   "source": [
    "df_predictions = pd.DataFrame(pd.Series(name='prediction', dtype='int64'))\n",
    "for i in range(0, stop, stepSize):\n",
    "   dfPartialResults = pd.read_csv(pathToDataFiles + subfolderPredictions + 'naive-bayes-N-Grams-' + str(n) + '-predictions-' + str(i) + '-' + dataset, sep='\\t')\n",
    "   df_predictions = pd.concat([df_predictions, dfPartialResults], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngrams</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>TPTN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(trump, says), (says, russia), (russia, probe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(trudeau, sees), (sees, flood), (flood, ameri...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(lawsuit, filed), (filed, baltimore), (baltim...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(u.s., quits), (quits, talks), (talks, global...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(senate, 's), ('s, cia), (cia, torture), (tor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ngrams  label  prediction   TPTN\n",
       "0  [(trump, says), (says, russia), (russia, probe...    0.0         0.0   True\n",
       "1  [(trudeau, sees), (sees, flood), (flood, ameri...    0.0         0.0   True\n",
       "2  [(lawsuit, filed), (filed, baltimore), (baltim...    0.0         1.0  False\n",
       "3  [(u.s., quits), (quits, talks), (talks, global...    1.0         0.0  False\n",
       "4  [(senate, 's), ('s, cia), (cia, torture), (tor...    NaN         NaN    NaN"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_ng = pd.DataFrame(val.ngrams)\n",
    "df_results_ng['label'] = y_val\n",
    "df_results_ng['prediction'] = df_predictions.prediction\n",
    "df_results_ng['TPTN'] = df_results_ng.label == df_results_ng.prediction\n",
    "df_results_ng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_ng.to_csv('naive-bayes-N-Grams-' + str(n) + '-results-' + dataset, sep='\\t', index=False)\n",
    "df_results_ng = pd.read_csv('naive-bayes-N-Grams-' + str(n) + '-results-' + dataset, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd17a11ea7543847da29bd4e1a3a09b21faff0b9e29eed5ea605d70fe73d28e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
